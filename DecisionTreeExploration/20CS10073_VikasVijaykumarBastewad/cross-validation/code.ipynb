{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2 - Cross Validation\n",
    "### Name: Vikas Vijaykumar Bastewad\n",
    "### Roll Number: 20CS10073"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "K-fold cross-validation is a technique used to assess and optimize the performance of machine\n",
    "learning models. The dataset is divided into K subsets, or ”folds.” The model is trained on K-1 folds\n",
    "and tested on the remaining one. This process is repeated K times, and the average performance\n",
    "is used to gauge the model’s generalization ability.\n",
    "For this assignment,\n",
    "1. Split the dataset into 80% for training and 20% for testing. Normalize/Regularize data if\n",
    "necessary. Encode categorical variables using appropriate encoding method if necessary.\n",
    "2. Train a Logistic Regression model on the dataset using saga solver from scikit-learn\n",
    "package and using no regularization penalty.\n",
    "3. Cross Validate the classifier with 5-folds and print the mean accuracy, precision and\n",
    "recall for the class 1(good) for the classifier. You may or may not use the scikit-learn\n",
    "implementations for computing these metrics. However, you cannot use any ML package\n",
    "for the cross validation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Suppress FutureWarnings and ConvergenceWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data\n",
    "df = pd.read_csv('../../dataset/cross-validation.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical variables using one-hot encoding\n",
    "df = pd.get_dummies(df, columns=[\"Gender\", \"Married\", \"Education\", \"Self_Employed\", \"Property_Area\", \"Loan_Status\"], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the dataset into training (80%) and testing (20%) sets\n",
    "train_size = int(0.8 * len(df))\n",
    "train_data = df[:train_size]\n",
    "test_data = df[train_size:]\n",
    "\n",
    "X_train = train_data.drop(columns=[\"Loan_Status_Y\"])\n",
    "y_train = train_data[\"Loan_Status_Y\"]\n",
    "X_test = test_data.drop(columns=[\"Loan_Status_Y\"])\n",
    "y_test = test_data[\"Loan_Status_Y\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training  Logistic Regression model using the Saga solver with no regularization\n",
    "\n",
    "# Droping the non-numeric columns (e.g., 'Loan_ID') before training\n",
    "X_train_numeric = X_train.select_dtypes(include=['number'])\n",
    "\n",
    "# Imputing the missing values with the mean to avoid errors during training that may be caused by missing values\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "X_train_numeric_imputed = imputer.fit_transform(X_train_numeric) \n",
    "\n",
    "# Training the model using the training set and the LogisticRegression class from scikit-learn\n",
    "model = LogisticRegression(solver='saga', penalty='none', random_state=42)\n",
    "model.fit(X_train_numeric_imputed, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of folds (K)\n",
    "K = 5\n",
    "\n",
    "# Calculate fold size\n",
    "fold_size = len(X_train_numeric_imputed) // K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Fold  1\n",
      "-Accuracy: 0.7857142857142857\n",
      "-Precision: 0.7469879518072289\n",
      "-Recall: 1.0\n",
      "\n",
      "Metrics for Fold  2\n",
      "-Accuracy: 0.7551020408163265\n",
      "-Precision: 0.7682926829268293\n",
      "-Recall: 0.9264705882352942\n",
      "\n",
      "Metrics for Fold  3\n",
      "-Accuracy: 0.7755102040816326\n",
      "-Precision: 0.788235294117647\n",
      "-Recall: 0.9436619718309859\n",
      "\n",
      "Metrics for Fold  4\n",
      "-Accuracy: 0.826530612244898\n",
      "-Precision: 0.813953488372093\n",
      "-Recall: 0.9859154929577465\n",
      "\n",
      "Metrics for Fold  5\n",
      "-Accuracy: 0.8469387755102041\n",
      "-Precision: 0.8205128205128205\n",
      "-Recall: 0.9846153846153847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lists to store the metrics across each folds\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Performing K-fold cross-validation\n",
    "for fold in range(K):\n",
    "    # Defining the validation fold\n",
    "    validation_start = fold * fold_size\n",
    "    validation_end = (fold + 1) * fold_size\n",
    "    \n",
    "    # Creating the training and validation sets\n",
    "    X_train_fold = np.concatenate([X_train_numeric_imputed[:validation_start], X_train_numeric_imputed[validation_end:]], axis=0)\n",
    "    y_train_fold = pd.concat([y_train[:validation_start], y_train[validation_end:]], axis=0)\n",
    "    X_val_fold = X_train_numeric_imputed[validation_start:validation_end]\n",
    "    y_val_fold = y_train[validation_start:validation_end]\n",
    "    \n",
    "    # Standardize the data (mean=0, std=1) using training data to avoid data leakage\n",
    "    scaler = StandardScaler()\n",
    "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Training the model on the training fold \n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Now Predicting on the validation fold \n",
    "    y_pred_fold = model.predict(X_val_fold)\n",
    "\n",
    "    # Calculating and storing the metrics for this fold\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    accuracy_scores.append(accuracy) \n",
    "\n",
    "    precision = precision_score(y_val_fold, y_pred_fold) \n",
    "    precision_scores.append(precision)\n",
    "\n",
    "    recall = recall_score(y_val_fold, y_pred_fold)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    # Printing the Metrics for this fold\n",
    "    print(\"Metrics for Fold %2d\" % (fold + 1))\n",
    "    print(f\"-Accuracy: {accuracy}\")\n",
    "    print(f\"-Precision: {precision}\")\n",
    "    print(f\"-Recall: {recall}\")\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing Mean Metrics for all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics\n",
      "-Mean Accuracy: 0.7979591836734694\n",
      "-Mean Precision: 0.7875964475473237\n",
      "-Mean Recall: 0.9681326875278822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Metrics\")\n",
    "print(f\"-Mean Accuracy: {np.mean(accuracy_scores)}\")\n",
    "print(f\"-Mean Precision: {np.mean(precision_scores)}\")\n",
    "print(f\"-Mean Recall: {np.mean(recall_scores)}\")\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
